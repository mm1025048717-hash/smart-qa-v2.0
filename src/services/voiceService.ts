// DataAgent è¯­éŸ³æœåŠ¡ - WebSocket å®¢æˆ·ç«¯
// è¿æ¥ Pipecat åç«¯ï¼Œå®ç°è¯­éŸ³è¾“å…¥/è¾“å‡º

export interface VoiceServiceConfig {
  wsUrl?: string;
  agentId?: string;
  onTranscript?: (text: string) => void;
  onAudioData?: (audio: ArrayBuffer) => void;
  onError?: (error: Error) => void;
  onConnected?: () => void;
  onDisconnected?: () => void;
}

export class VoiceService {
  private ws: WebSocket | null = null;
  private audioContext: AudioContext | null = null;
  private mediaStream: MediaStream | null = null;
  private isRecording = false;
  private isMuted = false;
  private gainNode: GainNode | null = null;
  private config: VoiceServiceConfig;
  private connectionAttempts = 0;
  private maxConnectionAttempts = 2; // å‡å°‘åˆ°2æ¬¡ï¼Œé¿å…è¿‡å¤šå°è¯•
  private lastErrorTime = 0;
  private errorThrottleMs = 10000; // å¢åŠ åˆ°10ç§’ï¼Œå‡å°‘é”™è¯¯é¢‘ç‡
  private shouldRetry = true; // æ˜¯å¦åº”è¯¥é‡è¯•è¿æ¥
  private audioQueue: AudioBuffer[] = []; // éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—
  private isPlaying = false; // æ˜¯å¦æ­£åœ¨æ’­æ”¾
  private nextPlayTime = 0; // ä¸‹ä¸€ä¸ªéŸ³é¢‘å—çš„æ’­æ”¾æ—¶é—´
  private recordingAudioContext: AudioContext | null = null; // å½•éŸ³ä¸“ç”¨çš„ AudioContext
  private scriptProcessor: ScriptProcessorNode | null = null; // ScriptProcessorNode å¼•ç”¨
  private audioSource: MediaStreamAudioSourceNode | null = null; // éŸ³é¢‘æºå¼•ç”¨

  constructor(config: VoiceServiceConfig = {}) {
    this.config = {
      wsUrl: config.wsUrl || 'ws://localhost:8765',
      agentId: config.agentId || 'alisa',
      ...config,
    };
  }

  // é‡ç½®è¿æ¥çŠ¶æ€ï¼ˆå…è®¸é‡æ–°å°è¯•è¿æ¥ï¼‰
  resetConnectionState(): void {
    this.connectionAttempts = 0;
    this.shouldRetry = true;
    this.lastErrorTime = 0;
  }

  // åˆå§‹åŒ– AudioContextï¼ˆåœ¨ç”¨æˆ·äº¤äº’æ—¶è°ƒç”¨ï¼‰
  private initAudioContext(): void {
    if (!this.audioContext || this.audioContext.state === 'closed') {
      console.log('[VoiceService] Creating AudioContext');
      this.audioContext = new AudioContext({ sampleRate: 24000 });
      this.gainNode = this.audioContext.createGain();
      this.gainNode.gain.value = 1.0;
      this.gainNode.connect(this.audioContext.destination);
      
      // å¦‚æœ AudioContext å¤„äº suspended çŠ¶æ€ï¼Œå°è¯• resumeï¼ˆéœ€è¦åœ¨ç”¨æˆ·äº¤äº’åï¼‰
      if (this.audioContext.state === 'suspended') {
        this.audioContext.resume().then(() => {
          console.log('[VoiceService] AudioContext resumed, state:', this.audioContext?.state);
        }).catch((error) => {
          console.warn('[VoiceService] Failed to resume AudioContext:', error);
        });
      }
      console.log('[VoiceService] AudioContext created, state:', this.audioContext.state);
    }
  }

  // è¿æ¥åˆ° WebSocket æœåŠ¡å™¨
  async connect(): Promise<void> {
    return new Promise((resolve, reject) => {
      // å¦‚æœå·²ç»è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
      if (this.connectionAttempts >= this.maxConnectionAttempts && !this.shouldRetry) {
        const err = new Error(
          `è¯­éŸ³æœåŠ¡ä¸å¯ç”¨ã€‚è¯·å¯åŠ¨è¯­éŸ³æœåŠ¡åé‡è¯•ã€‚\n` +
          `è¿è¡Œ: voice-backend\\å¯åŠ¨æœåŠ¡.bat æˆ– ä¸€é”®å¯åŠ¨è¯­éŸ³æœåŠ¡.bat`
        );
        reject(err);
        return;
      }

      try {
        const wsUrl = this.config.wsUrl || 'ws://localhost:8765';
        
        // å¦‚æœå·²ç»æœ‰ WebSocket è¿æ¥ï¼Œå…ˆå…³é—­å¹¶ç­‰å¾…
        if (this.ws && this.ws.readyState !== WebSocket.CLOSED) {
          this.ws.close();
          // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿è¿æ¥å·²å…³é—­
          setTimeout(() => {
            this.attemptConnect(wsUrl, resolve, reject);
          }, 100);
        } else {
          this.attemptConnect(wsUrl, resolve, reject);
        }
      } catch (error) {
        console.error('[VoiceService] Connection exception:', error);
        reject(error);
      }
    });
  }

  private attemptConnect(wsUrl: string, resolve: () => void, reject: (error: Error) => void): void {
    this.connectionAttempts++;
    
    // åªåœ¨é¦–æ¬¡è¿æ¥æ—¶è®°å½•æ—¥å¿—
    if (this.connectionAttempts === 1) {
      console.log(`[VoiceService] Connecting to ${wsUrl}...`);
    }

    this.ws = new WebSocket(wsUrl);
    // è®¾ç½® binaryType ä¸º 'arraybuffer' ä»¥æ¥æ”¶éŸ³é¢‘æ•°æ®
    this.ws.binaryType = 'arraybuffer';

    // è®¾ç½®è¿æ¥è¶…æ—¶ï¼ˆ10ç§’ï¼‰
    const timeout = setTimeout(() => {
      if (this.ws?.readyState !== WebSocket.OPEN) {
        this.ws?.close();
        const err = new Error(`WebSocket connection timeout: ${wsUrl}`);
        // èŠ‚æµé”™è¯¯æ—¥å¿—
        this.logErrorOnce(err.message);
        // åªåœ¨é¦–æ¬¡è¶…æ—¶æ—¶è°ƒç”¨ onError
        if (this.connectionAttempts === 1) {
          this.config.onError?.(err);
        }
        reject(err);
      }
    }, 10000);

    this.ws.onopen = () => {
      clearTimeout(timeout);
      // è¿æ¥æˆåŠŸï¼Œé‡ç½®æ‰€æœ‰çŠ¶æ€
      this.connectionAttempts = 0;
      this.lastErrorTime = 0;
      this.shouldRetry = true;
      console.log('[VoiceService] WebSocket connected');
      // ä¸åœ¨ onopen æ—¶åˆå§‹åŒ– AudioContextï¼Œéœ€è¦åœ¨ç”¨æˆ·äº¤äº’ååˆå§‹åŒ–
      // AudioContext ä¼šåœ¨ startRecording æ—¶ç”±ç”¨æˆ·æ‰‹åŠ¿è§¦å‘åˆå§‹åŒ–
      this.config.onConnected?.();
      resolve();
    };

    this.ws.onerror = (error) => {
      clearTimeout(timeout);
      // è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°åï¼Œåœæ­¢è‡ªåŠ¨é‡è¯•
      if (this.connectionAttempts >= this.maxConnectionAttempts) {
        this.shouldRetry = false;
      }
      // å®Œå…¨é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
      const err = new Error('è¯­éŸ³æœåŠ¡ä¸å¯ç”¨');
      // åªåœ¨é¦–æ¬¡é”™è¯¯æ—¶è°ƒç”¨ onErrorï¼Œé¿å…é‡å¤è§¦å‘
      if (this.connectionAttempts === 1) {
        this.config.onError?.(err);
      }
      reject(err);
    };

    this.ws.onclose = (event) => {
      clearTimeout(timeout);
      // åªåœ¨æ­£å¸¸å…³é—­æ—¶è®°å½•æ—¥å¿—
      if (event.code === 1000 || event.code === 1001) {
        console.log('[VoiceService] WebSocket disconnected', event.code, event.reason);
      }
      this.config.onDisconnected?.();
      // å¦‚æœä¸æ˜¯æ­£å¸¸å…³é—­ï¼Œä¸åœ¨è¿™é‡Œé‡è¿ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨è§¦å‘
    };

    this.ws.onmessage = (event) => {
      this.handleMessage(event);
    };
  }

  // èŠ‚æµé”™è¯¯æ—¥å¿—ï¼Œé¿å…é‡å¤è¾“å‡º
  private logErrorOnce(message: string) {
    const now = Date.now();
    if (now - this.lastErrorTime > this.errorThrottleMs) {
      // ä½¿ç”¨ console.debug è€Œä¸æ˜¯ console.warnï¼Œå‡å°‘æ§åˆ¶å°å™ªéŸ³
      // åªåœ¨å¼€å‘ç¯å¢ƒæ˜¾ç¤ºè¯¦ç»†é”™è¯¯
      if (import.meta.env.DEV) {
        console.debug('[VoiceService]', message);
      }
      this.lastErrorTime = now;
    }
  }

  // å¤„ç† WebSocket æ¶ˆæ¯
  private handleMessage(event: MessageEvent) {
    if (event.data instanceof ArrayBuffer) {
      // æ£€æŸ¥æ˜¯å¦æ˜¯ WAV æ ¼å¼ï¼ˆä»¥ "RIFF" å¼€å¤´ï¼‰
      const dataView = new DataView(event.data);
      const isWav = event.data.byteLength >= 4 && 
                    String.fromCharCode(dataView.getUint8(0), dataView.getUint8(1), dataView.getUint8(2), dataView.getUint8(3)) === 'RIFF';
      
      if (isWav) {
        // WAV éŸ³é¢‘æ•°æ®ï¼Œç›´æ¥æ’­æ”¾
        console.log('[VoiceService] Received WAV audio data:', event.data.byteLength, 'bytes');
        this.config.onAudioData?.(event.data);
        this.playAudio(event.data);
      } else {
        // å°è¯•è§£æä¸º JSON æ–‡æœ¬æ¶ˆæ¯ï¼ˆè½¬å½•ç»“æœç­‰ï¼‰
        try {
          const text = new TextDecoder().decode(event.data);
          const data = JSON.parse(text);
          if (data.type === 'transcript') {
            this.config.onTranscript?.(data.text);
          } else if (import.meta.env.DEV) {
            // åªåœ¨å¼€å‘ç¯å¢ƒè®°å½•å…¶ä»–æ–‡æœ¬æ¶ˆæ¯
            console.log('[VoiceService] Received text message:', data);
          }
        } catch (e) {
          // ä¸æ˜¯æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯ Protobuf ç¼–ç çš„ééŸ³é¢‘å¸§ï¼ˆmetrics, RTVI ç­‰ï¼‰
          // è¿™äº›å¸§ä¸éœ€è¦å¤„ç†ï¼Œé™é»˜å¿½ç•¥
          if (import.meta.env.DEV) {
            // åªåœ¨å¼€å‘ç¯å¢ƒè®°å½•ï¼Œä½¿ç”¨ debug çº§åˆ«
            console.debug('[VoiceService] Ignoring non-audio binary frame (likely Protobuf)', event.data.byteLength, 'bytes');
          }
        }
      }
    } else if (typeof event.data === 'string') {
      // æ–‡æœ¬æ•°æ®ï¼ˆè½¬å½•ç»“æœç­‰ï¼‰
      try {
        const data = JSON.parse(event.data);
        if (data.type === 'transcript') {
          this.config.onTranscript?.(data.text);
        } else if (import.meta.env.DEV) {
          console.log('[VoiceService] Received text message:', data);
        }
      } catch (e) {
        // æ™®é€šæ–‡æœ¬æ¶ˆæ¯
        this.config.onTranscript?.(event.data);
      }
    } else if (event.data instanceof Blob) {
      // å¤„ç† Blob ç±»å‹çš„éŸ³é¢‘æ•°æ®
      event.data.arrayBuffer().then((buffer) => {
        console.log('[VoiceService] Received audio blob:', buffer.byteLength, 'bytes');
        this.config.onAudioData?.(buffer);
        this.playAudio(buffer);
      });
    } else if (import.meta.env.DEV) {
      // åªåœ¨å¼€å‘ç¯å¢ƒè®°å½•æœªçŸ¥æ¶ˆæ¯ç±»å‹
      console.debug('[VoiceService] Unknown message type:', typeof event.data);
    }
  }

  // æ’­æ”¾éŸ³é¢‘
  private async playAudio(audioData: ArrayBuffer) {
    if (this.isMuted) {
      console.log('[VoiceService] âš ï¸ Audio muted, skipping playback');
      return;
    }

    if (!audioData || audioData.byteLength === 0) {
      console.warn('[VoiceService] Empty audio data, skipping');
      return;
    }

    console.log('[VoiceService] ğŸ”Š Starting audio playback, data size:', audioData.byteLength, 'bytes');

    try {
      // ç¡®ä¿ AudioContext å·²åˆ›å»ºä¸”å¤„äºè¿è¡ŒçŠ¶æ€
      if (!this.audioContext || this.audioContext.state === 'closed') {
        console.log('[VoiceService] Creating AudioContext for playback...');
        this.initAudioContext();
      }

      // å¦‚æœ AudioContext è¢«æš‚åœï¼Œå°è¯•æ¢å¤å®ƒï¼ˆéœ€è¦åœ¨ç”¨æˆ·äº¤äº’åï¼‰
      if (this.audioContext && this.audioContext.state === 'suspended') {
        console.log('[VoiceService] âš ï¸ AudioContext suspended, attempting to resume...');
        try {
          await this.audioContext.resume();
          console.log('[VoiceService] âœ… AudioContext resumed, state:', this.audioContext.state);
        } catch (error) {
          console.warn('[VoiceService] âŒ Failed to resume AudioContext (may need user interaction):', error);
          // å¦‚æœæ¢å¤å¤±è´¥ï¼Œä»ç„¶å°è¯•è§£ç ï¼ˆå¯èƒ½ä¼šå¤±è´¥ï¼Œä½†ä¸é˜»å¡ï¼‰
        }
      }

      if (!this.audioContext || this.audioContext.state === 'closed') {
        console.warn('[VoiceService] âŒ AudioContext not available, skipping audio playback. State:', this.audioContext?.state || 'null');
        return;
      }

      console.log('[VoiceService] âœ… AudioContext ready, state:', this.audioContext.state);

      // è§£ç  WAV éŸ³é¢‘æ•°æ®
      const audioBuffer = await this.audioContext.decodeAudioData(audioData.slice(0));
      console.log('[VoiceService] Audio decoded:', {
        channels: audioBuffer.numberOfChannels,
        sampleRate: audioBuffer.sampleRate,
        duration: audioBuffer.duration.toFixed(2) + 's',
        length: audioBuffer.length
      });
      
      // å°†éŸ³é¢‘ç¼“å†²æ·»åŠ åˆ°é˜Ÿåˆ—
      this.audioQueue.push(audioBuffer);
      console.log('[VoiceService] Audio buffer added to queue, queue length:', this.audioQueue.length);
      
      // å¦‚æœå½“å‰æ²¡æœ‰æ’­æ”¾ï¼Œå¼€å§‹æ’­æ”¾é˜Ÿåˆ—
      if (!this.isPlaying) {
        this.playAudioQueue();
      }
    } catch (error) {
      console.error('[VoiceService] Error processing audio:', error);
      if (error instanceof Error) {
        console.error('[VoiceService] Error details:', {
          name: error.name,
          message: error.message
        });
      }
    }
  }

  // æ’­æ”¾éŸ³é¢‘é˜Ÿåˆ—
  private playAudioQueue() {
    if (this.isPlaying || this.audioQueue.length === 0 || !this.audioContext || this.audioContext.state === 'closed') {
      return;
    }

    this.isPlaying = true;
    this.playNextAudioBuffer();
  }

  // æ’­æ”¾ä¸‹ä¸€ä¸ªéŸ³é¢‘ç¼“å†²
  private playNextAudioBuffer() {
    if (!this.audioContext || this.audioContext.state === 'closed') {
      this.isPlaying = false;
      this.audioQueue = [];
      this.nextPlayTime = 0;
      console.warn('[VoiceService] AudioContext closed, clearing queue');
      return;
    }

    if (this.audioQueue.length === 0) {
      this.isPlaying = false;
      this.nextPlayTime = 0;
      console.log('[VoiceService] Audio queue playback completed');
      return;
    }

    const audioBuffer = this.audioQueue.shift();
    if (!audioBuffer) {
      this.playNextAudioBuffer();
      return;
    }

    try {
      const source = this.audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(this.gainNode!);

      // è®¡ç®—æ’­æ”¾æ—¶é—´ï¼Œç¡®ä¿è¿ç»­æ’­æ”¾
      const currentTime = this.audioContext.currentTime;
      const startTime = Math.max(currentTime, this.nextPlayTime);

      source.onended = () => {
        // å½“å‰éŸ³é¢‘æ’­æ”¾å®Œæˆï¼Œæ’­æ”¾ä¸‹ä¸€ä¸ª
        this.playNextAudioBuffer();
      };

      source.onerror = (error) => {
        console.error('[VoiceService] Audio source error:', error);
        // å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­æ’­æ”¾ä¸‹ä¸€ä¸ª
        this.playNextAudioBuffer();
      };

      source.start(startTime);
      this.nextPlayTime = startTime + audioBuffer.duration;
      console.log('[VoiceService] Playing audio buffer, duration:', audioBuffer.duration.toFixed(2), 's');
    } catch (error) {
      console.error('[VoiceService] Error playing audio from queue:', error);
      // å‡ºé”™æ—¶ç»§ç»­æ’­æ”¾ä¸‹ä¸€ä¸ª
      this.playNextAudioBuffer();
    }
  }

  // è®¾ç½®é™éŸ³çŠ¶æ€
  setMuted(muted: boolean): void {
    this.isMuted = muted;
    if (this.gainNode) {
      this.gainNode.gain.value = muted ? 0 : 1;
    }
  }

  // è·å–é™éŸ³çŠ¶æ€
  getMuted(): boolean {
    return this.isMuted;
  }

  // å¼€å§‹å½•éŸ³
  async startRecording(): Promise<void> {
    if (this.isRecording) {
      console.warn('[VoiceService] Already recording');
      return;
    }

    try {
      // åœ¨ç”¨æˆ·äº¤äº’æ—¶åˆå§‹åŒ– AudioContextï¼ˆè§£é”éŸ³é¢‘æ’­æ”¾ï¼‰
      this.initAudioContext();
      
      // è¯·æ±‚éº¦å…‹é£æƒé™
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
        },
      });

      this.isRecording = true;

      // åˆ›å»ºå½•éŸ³ä¸“ç”¨çš„ AudioContextï¼ˆä¸æ’­æ”¾ç”¨çš„åˆ†å¼€ï¼‰
      this.recordingAudioContext = new AudioContext({ sampleRate: 16000 });
      this.audioSource = this.recordingAudioContext.createMediaStreamSource(this.mediaStream);
      this.scriptProcessor = this.recordingAudioContext.createScriptProcessor(4096, 1, 1);

      let audioChunkCount = 0;
      this.scriptProcessor.onaudioprocess = (e) => {
        if (this.isRecording && this.ws?.readyState === WebSocket.OPEN) {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcmData = new Int16Array(inputData.length);
          
          // è½¬æ¢ä¸º PCM 16-bit
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }

          // å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
          try {
            this.ws?.send(pcmData.buffer);
            audioChunkCount++;
            // æ¯100ä¸ªchunkè®°å½•ä¸€æ¬¡æ—¥å¿—ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
            if (audioChunkCount % 100 === 0) {
              console.log(`[VoiceService] Sent ${audioChunkCount} audio chunks`);
            }
          } catch (error) {
            console.error('[VoiceService] Error sending audio data:', error);
          }
        }
      };

      this.audioSource.connect(this.scriptProcessor);
      this.scriptProcessor.connect(this.recordingAudioContext.destination);

      console.log('[VoiceService] Recording started, AudioContext sampleRate:', this.recordingAudioContext.sampleRate);
    } catch (error) {
      console.error('[VoiceService] Error starting recording:', error);
      this.isRecording = false;
      // æ¸…ç†èµ„æº
      this.cleanupRecording();
      throw error;
    }
  }

  // æ¸…ç†å½•éŸ³èµ„æº
  private cleanupRecording(): void {
    if (this.scriptProcessor) {
      try {
        this.scriptProcessor.disconnect();
        this.scriptProcessor = null;
      } catch (e) {
        console.warn('[VoiceService] Error disconnecting script processor:', e);
      }
    }

    if (this.audioSource) {
      try {
        this.audioSource.disconnect();
        this.audioSource = null;
      } catch (e) {
        console.warn('[VoiceService] Error disconnecting audio source:', e);
      }
    }

    if (this.recordingAudioContext) {
      try {
        if (this.recordingAudioContext.state !== 'closed') {
          this.recordingAudioContext.close();
        }
        this.recordingAudioContext = null;
      } catch (e) {
        console.warn('[VoiceService] Error closing recording AudioContext:', e);
      }
    }
  }

  // åœæ­¢å½•éŸ³
  stopRecording(): void {
    if (!this.isRecording) {
      return;
    }

    this.isRecording = false;

    // æ¸…ç†å½•éŸ³ç›¸å…³çš„éŸ³é¢‘å¤„ç†èŠ‚ç‚¹
    this.cleanupRecording();

    // åœæ­¢åª’ä½“æµ
    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach((track) => {
        track.stop();
        console.log('[VoiceService] Stopped media track:', track.kind, track.label);
      });
      this.mediaStream = null;
    }

    console.log('[VoiceService] Recording stopped');
  }

  // æ–­å¼€è¿æ¥
  disconnect(): void {
    this.stopRecording();

    // æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
    this.audioQueue = [];
    this.isPlaying = false;
    this.nextPlayTime = 0;

    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }

    // åªå…³é—­æ’­æ”¾ç”¨çš„ AudioContextï¼Œå½•éŸ³ç”¨çš„å·²ç»åœ¨ stopRecording ä¸­å…³é—­
    if (this.audioContext && this.audioContext.state !== 'closed') {
      this.audioContext.close();
      this.audioContext = null;
      this.gainNode = null;
    }
  }

  // æ£€æŸ¥æ˜¯å¦å·²è¿æ¥
  isConnected(): boolean {
    return this.ws?.readyState === WebSocket.OPEN;
  }

  // æ£€æŸ¥æ˜¯å¦æ­£åœ¨å½•éŸ³
  getIsRecording(): boolean {
    return this.isRecording;
  }
}


